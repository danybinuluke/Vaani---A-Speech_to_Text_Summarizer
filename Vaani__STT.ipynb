{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers librosa gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import librosa\n",
        "\n",
        "# Define models and processors for ASR, Translation, and Summarization\n",
        "asr_models = {\n",
        "    \"hindi\": {\n",
        "        \"processor\": Wav2Vec2Processor.from_pretrained(\"ai4bharat/indicwav2vec-hindi\"),\n",
        "        \"model\": Wav2Vec2ForCTC.from_pretrained(\"ai4bharat/indicwav2vec-hindi\")\n",
        "    },\n",
        "    \"english\": {\n",
        "        \"processor\": Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\"),\n",
        "        \"model\": Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "    },\n",
        "    \"malayalam\": {\n",
        "        \"processor\": Wav2Vec2Processor.from_pretrained(\"gvs/wav2vec2-large-xlsr-malayalam\"),\n",
        "        \"model\": Wav2Vec2ForCTC.from_pretrained(\"gvs/wav2vec2-large-xlsr-malayalam\")\n",
        "    }\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ1Qg34j-MdI",
        "outputId": "9769f2f9-4db5-4aef-94c4-326796251c8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:311: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ASR Models which will be used to transcribe the respective languages"
      ],
      "metadata": {
        "id": "4xRSr9Zi_9_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translation_models = {\n",
        "    \"hindi\": AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-hi-en\"),\n",
        "    \"malayalam\": AutoModelForSeq2SeqLM.from_pretrained(\"ArunIcfoss/mbart-large-50-many-to-many-mmt-ICFOSS-Malayalam_English_Translation\")\n",
        "}\n",
        "translation_tokenizers = {\n",
        "    \"hindi\": AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-hi-en\"),\n",
        "    \"malayalam\": AutoTokenizer.from_pretrained(\"ArunIcfoss/mbart-large-50-many-to-many-mmt-ICFOSS-Malayalam_English_Translation\")\n",
        "}\n",
        "\n",
        "summarization_models = {\n",
        "    \"hindi\": AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-base\"),\n",
        "    \"english\": AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\"),\n",
        "    \"malayalam\": AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART\")\n",
        "}\n",
        "summarization_tokenizers = {\n",
        "    \"hindi\": AutoTokenizer.from_pretrained(\"google/mt5-base\"),\n",
        "    \"english\": AutoTokenizer.from_pretrained(\"t5-base\"),\n",
        "    \"malayalam\": AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\")\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWpjBM6iAKjk",
        "outputId": "7e613e56-fa7a-4221-baaf-251b1217f878"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Translation and Summarizing Models For the Respective Regional as well as Global Language"
      ],
      "metadata": {
        "id": "p8fHYWXMAbLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_output(text):\n",
        "    return text.replace(\"<extra_id_0>\", \"\").replace(\"<tero_id_0>\", \"\").strip()\n",
        "\n",
        "# Function for transcription\n",
        "def transcribe_audio(audio_path, language):\n",
        "    try:\n",
        "        # Load audio file\n",
        "        audio, sr = librosa.load(audio_path, sr=16000)\n",
        "        if sr != 16000:\n",
        "            return \"Error: Audio sampling rate must be 16 kHz.\"\n",
        "\n",
        "        # Process the audio\n",
        "        processor = asr_models[language][\"processor\"]\n",
        "        model = asr_models[language][\"model\"]\n",
        "        input_values = processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
        "\n",
        "        # Get predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_values).logits\n",
        "\n",
        "        # Decode transcription\n",
        "        predicted_ids = torch.argmax(logits, dim=-1)\n",
        "        transcription = processor.batch_decode(predicted_ids)[0]\n",
        "        return transcription\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Transcription Error: {str(e)}\"\n",
        "\n",
        "# Function for translation\n",
        "def translate_text(text, source_language, target_language):\n",
        "    try:\n",
        "        tokenizer = translation_tokenizers[source_language]\n",
        "        model = translation_models[source_language]\n",
        "\n",
        "        # Tokenize input text\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "        # Generate translation\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=512,\n",
        "            num_beams=5,\n",
        "            repetition_penalty=1.5,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "\n",
        "        # Decode the translation\n",
        "        translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return translation\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Translation Error: {str(e)}\"\n",
        "\n",
        "# Function for summarization\n",
        "def summarize_text(text, language):\n",
        "    try:\n",
        "        tokenizer = summarization_tokenizers[language]\n",
        "        model = summarization_models[language]\n",
        "\n",
        "        # Prepare input for summarization\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "\n",
        "        # Generate summary\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=150,\n",
        "            num_beams=5,\n",
        "            repetition_penalty=2.0,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "\n",
        "        # Decode and clean up the summary\n",
        "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return clean_output(summary)  # Clean output\n",
        "    except Exception as e:\n",
        "        return f\"Summarization Error: {str(e)}\"\n",
        "\n",
        "# Updated process_audio function to handle matching languages\n",
        "def process_audio(audio_path, language, target_lang):\n",
        "    transcription = transcribe_audio(audio_path, language)\n",
        "    if \"Error\" in transcription:\n",
        "        return transcription, \"N/A\", \"N/A\", \"N/A\"\n",
        "\n",
        "    # If source language and target language are the same, set translation and summaries to N/A\n",
        "    if language == target_lang:\n",
        "        translation = \"N/A\"\n",
        "        source_summary = summarize_text(transcription, language)\n",
        "        target_summary = \"N/A\"\n",
        "    else:\n",
        "        # Translate transcription directly\n",
        "        translation = translate_text(transcription, language, target_lang)\n",
        "        # Summarize in the source language\n",
        "        source_summary = summarize_text(transcription, language)\n",
        "        # Translate the source summary to the target language\n",
        "        target_summary = translate_text(source_summary, language, target_lang)\n",
        "\n",
        "    return transcription, translation, source_summary, clean_output(target_summary)\n",
        "\n"
      ],
      "metadata": {
        "id": "OYz_673aAi1E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Necessary Functions for Transcribing,Translating and Summarizing the Inputted Audio"
      ],
      "metadata": {
        "id": "I0oVfiYqApws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_interface(audio, language, target_lang):\n",
        "    return process_audio(audio, language, target_lang)\n",
        "\n",
        "# Launch Gradio App\n",
        "interface = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=[\n",
        "        gr.Audio(type=\"filepath\", label=\"Upload Audio File\"),\n",
        "        gr.Dropdown(choices=[\"hindi\", \"english\", \"malayalam\"], label=\"Source Language\"),\n",
        "        gr.Dropdown(choices=[\"english\", \"hindi\", \"malayalam\"], label=\"Target Language\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Transcription\"),\n",
        "        gr.Textbox(label=\"Translation of Transcription\"),\n",
        "        gr.Textbox(label=\"Source Summary\"),\n",
        "        gr.Textbox(label=\"Target Summary\")\n",
        "    ],\n",
        "    title=\"Vaani - A Speech-To-Text Summarizer\",\n",
        "    description=\"Upload an audio file, select the source language, and choose the target language. Outputs include transcription, its translation, and summaries in both languages.\"\n",
        ")\n",
        "\n",
        "interface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "rKmzJvUZAy26",
        "outputId": "7244c966-ce4b-4530-8834-99a453e15d47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a9fdc005bfd5844971.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a9fdc005bfd5844971.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://a9fdc005bfd5844971.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Web Interface where you can input the Audio and recieve outputs on the depending upon your requirements"
      ],
      "metadata": {
        "id": "C45YUtXiA0Tc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}